{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "540ceaad-989e-432f-92f5-c13c85af46cb",
   "metadata": {},
   "source": [
    "**Vision Model v0** \\\n",
    "Goal: Recognize images of numbers from a Hugging Face dataset with the appropriate labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b75a49-acda-4115-83c8-d6a4f299361b",
   "metadata": {},
   "source": [
    "**Data Wrangling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdf5f688-9af7-4d01-82ea-a5d44bb284c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\atman\\OneDrive\\Documents\\Repos\\weather-ai-app\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a88e48aa-2928-48bf-9486-8a10c8b2e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"ylecun/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fe6df27-3699-4eef-81c3-8762b67043b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 60000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6872d691-71f7-437e-8446-d919d576a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.cuda\n",
    "import numpy as np\n",
    "from numba import cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08936a5d-bff0-4b48-b0a7-8757eb41455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert pngs to tensors containing pixel values\n",
    "rows = 60000\n",
    "width = 28\n",
    "height = 28\n",
    "\n",
    "images = torch.empty((rows, width, height), dtype=torch.int64)\n",
    "for i, row in enumerate(ds['train'].select(range(rows))):\n",
    "    images[i] = torch.reshape(torch.tensor(list(row['image'].getdata())), (width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac20428-f4e1-4303-a80f-349319442f54",
   "metadata": {},
   "source": [
    "**Forward Propagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4381078-7668-4c80-9a14-789ede43cf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define kernels\n",
    "torch.manual_seed(3500)\n",
    "min_fence = -0.05\n",
    "max_fence = 0.2\n",
    "\n",
    "# initialize kernels with random values and transform them to range [-0.2, 0.2)\n",
    "kernel_layer_1 = torch.rand(2, 5, 5)\n",
    "kernel_layer_1 = kernel_layer_1 * (max_fence - min_fence) + min_fence\n",
    "\n",
    "kernel_layer_2 = torch.rand(2, 2, 3, 3)\n",
    "kernel_layer_2 = kernel_layer_2 * (max_fence - min_fence) + min_fence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1391225-cf8f-46f5-a785-6199d24567bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0364,  0.1154,  0.1450, -0.0022,  0.0593],\n",
      "         [ 0.0242,  0.0963,  0.0600,  0.0817,  0.0017],\n",
      "         [ 0.1528,  0.0777,  0.1599,  0.0273,  0.1158],\n",
      "         [ 0.0239,  0.0899,  0.0634, -0.0149, -0.0376],\n",
      "         [ 0.0950,  0.0329,  0.0358, -0.0314,  0.0032]],\n",
      "\n",
      "        [[ 0.1508,  0.0007,  0.0146,  0.1369,  0.1446],\n",
      "         [ 0.0624,  0.0093,  0.0758,  0.1156,  0.1740],\n",
      "         [ 0.0936,  0.0291,  0.1949,  0.1970,  0.0746],\n",
      "         [ 0.1263,  0.1895,  0.0419,  0.0308,  0.0056],\n",
      "         [ 0.1420,  0.1938,  0.1158,  0.0516,  0.1152]]])\n",
      "tensor([[[[-0.0397,  0.1152,  0.1942],\n",
      "          [ 0.1029,  0.1195,  0.1461],\n",
      "          [ 0.1586,  0.1036,  0.0433]],\n",
      "\n",
      "         [[-0.0214,  0.1368,  0.0798],\n",
      "          [ 0.1655,  0.0692,  0.0755],\n",
      "          [ 0.0826,  0.1665,  0.0806]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0009,  0.1110,  0.0878],\n",
      "          [ 0.1642, -0.0338,  0.1944],\n",
      "          [ 0.0488,  0.0842,  0.1228]],\n",
      "\n",
      "         [[ 0.0895, -0.0187,  0.1870],\n",
      "          [-0.0414,  0.0135,  0.0015],\n",
      "          [-0.0296,  0.1525,  0.1119]]]])\n"
     ]
    }
   ],
   "source": [
    "print(kernel_layer_1)\n",
    "print(kernel_layer_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5206aa57-a329-4208-99aa-03ac3d03641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transforms matrices into vectors, verifies than they are of the same length, \n",
    "then performs a convolution on the vectors by multiplying the corresponding \n",
    "components and taking the sum of those products\n",
    "\"\"\"\n",
    "def convolve(m1: torch.Tensor, m2: torch.Tensor) -> torch.Tensor:\n",
    "    if len(m1.shape) != 2 or len(m2.shape) != 2:\n",
    "        raise Exception(f\"Matrix m1 has a rank of {len(m1.shape)} and \" + \n",
    "                        f\"Matrix m2 has a rank of {len(m2.shape)}\")\n",
    "    if m1.shape[0] * m1.shape[1] != m2.shape[0] * m2.shape[1]:\n",
    "        raise Exception(\"Linear length of matrices are not equal\")\n",
    "    m1 = torch.reshape(m1, (-1,)) \n",
    "    m2 = torch.reshape(m2, (-1,))\n",
    "    return sum(m1 * m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63df77fb-c175-4521-85d6-364e5840e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc9f95ac-436d-4bfd-91a3-27e467b76dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traverse_image(image: torch.Tensor, kernel: torch.Tensor, step: int, activationf: str) -> torch.Tensor:\n",
    "    if len(kernel.shape) != 2:\n",
    "        raise Exception(f\"Kernel has a rank of {len(kernel.shape)}\")\n",
    "    if kernel.shape[0] % 2 == 0:\n",
    "        raise Exception(\"Kernel matrix rank is not odd\")\n",
    "        \n",
    "    width = kernel.shape[0]\n",
    "    output = []\n",
    "    \n",
    "    for i in range(0, image.shape[1] - width + 1, step):\n",
    "        for j in range(0, image.shape[0] - width + 1, step):\n",
    "            current = image[i:i+width,j:j+width]\n",
    "            convolution = convolve(current, kernel)\n",
    "            if activationf.lower() == 'relu':\n",
    "                func = torch.nn.ReLU()\n",
    "            elif activationf.lower() == 'sigmoid':\n",
    "                func = torch.nn.Sigmoid()\n",
    "            else:\n",
    "                raise Exception(f'Argument \"{activationf}\" is not a valid activation function')\n",
    "            output.append(func(convolution))\n",
    "                \n",
    "    output = torch.Tensor(output)\n",
    "    rank = int(math.sqrt(len(output)))\n",
    "    output = torch.reshape(output, (rank, rank))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff4a487-3617-4d10-b0e4-425e506dd79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = traverse_image(images[0], kernel_layer_1[0], 1, 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ca7c821-2bd0-4424-8d05-24cba3288633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 22])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c926f371-5a26-4adb-9c9f-acedc151dc57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
